# 模型设计与计算效率综述

除了参数量 (Params) 和计算量 (FLOPs) 之外，模型的实际推理速度（Latency）还受到多种因素的影响，如内存访问成本 (MAC)、并行度以及硬件优化程度。本文件总结了影响模型效率的关键指标和设计原则。

## 1. 理论指标 vs. 实际速度

- **FLOPs (浮点运算数)**: 衡量算法的复杂度，是理论指标。
- **MAC (内存访问成本)**: 衡量数据读写量，在带宽受限设备上至关重要。
- **Latency (延迟)**: 模型完成一次推理的实际耗时，是最终目标。

**重要结论**: FLOPs 低不代表速度快。相同的 FLOPs 下，并行度高、MAC 低的模型速度更快。

---

## 2. 影响效率的关键因素

### 2.1 网络设计的碎片化 (Fragmentation)

- **现象**: 网络结构中包含大量的分支（如 Inception 模块中的多路径）或复杂的串并联结构。
- **影响**:
    - **降低并行度**: 过多的分支导致 GPU 无法高效并行处理。
    - **增加开销**: 引入了额外的内核启动 (kernel launching) 和同步 (synchronization) 开销。
- **准则**: **网络的碎片化程度越高，速度越慢**（ShuffleNet G3）。虽然碎片化结构（如 NAS 搜索出的结构）可能有利于提高准确率，但不利于 GPU/CPU 的硬件效率。

### 2.2 逐元素操作 (Element-wise Operations)

- **定义**: 包括 ReLU、Sigmoid、AddTensor、AddBias 等激活函数或张量相加操作。
- **特性**:
    - FLOPs 极低（通常忽略不计）。
    - MAC 较高（需要读取整个特征图并写回）。
- **影响**: 在轻量级网络（如 ShuffleNet, MobileNet）中，Element-wise 操作的时间占比可能相当大。
- **准则**: **Element-wise 操作不可忽视**（ShuffleNet G4）。应尽量减少冗余的逐元素操作。

### 2.3 硬件相关优化

- **CUDNN 优化**: $3 \times 3$ 卷积通常被 CUDNN 库高度优化，效率远高于其他尺寸的卷积。
- **内存对齐**: 通道数通常设置为 2 的幂次（如 32, 64, 128），有利于内存对齐和 SIMD 指令集加速。

---

## 3. 总结：高效模型设计指南

1.  **平衡 FLOPs 与 MAC**: 不要盲目追求低 FLOPs，需同时考虑内存访问量。
2.  **输入输出通道相等**: 尽量保持 $1 \times 1$ 卷积的 $C_{in} = C_{out}$ 以最小化 MAC。
3.  **减少分组数**: 分组卷积虽然降低参数和计算量，但会增加 MAC，分组数不宜过大。
4.  **减少碎片化**: 简洁的串行结构通常比复杂的分支结构更高效。
5.  **关注 Element-wise 开销**: 激活函数和残差连接的相加操作也有成本。
