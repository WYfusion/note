# 高精度鸟声时频定位框架：解耦式分层定位方案

## 1. 目标与核心挑战

### 1.1. 工程目标

本方案旨在为1分钟、32kHz采样率的音频，提供极高精度的鸟声事件（Bird Call Event）定位。具体指标要求如下：

*   **时间定位精度**: 误差 ≤ 0.01秒 (10毫秒)。
*   **频率定位精度**: 误差 ≤ 10赫兹。
*   **适用对象**: 时长在0.1秒至0.4秒之间的典型鸟鸣。

### 1.2. 核心挑战

1.  **突破物理限制**: 同时达到10ms的时间分辨率和10Hz的频率分辨率，超出了标准短时傅里叶变换（STFT）的能力范围，直接面临**时间-频率不确定性原理**的制约。
2.  **巨大的计算成本**: 满足高频域分辨率要求的STFT参数，将导致生成的频谱图尺寸剧增，对内存和计算能力提出严峻挑战。
3.  **鲁棒性要求**: 方案必须在存在背景噪声的情况下，稳定地从信号中分离出精确的起止边界。

---

## 2. 总体设计：解耦式分层定位 (Decoupled Hierarchical Localization)

为应对时间-频率不确定性的物理限制，我们设计了一套解耦的、从宏观到微观的**四阶段**处理框架。该框架将频率定位和时间定位分解为两个独立优化的步骤。

```mermaid
graph TD
    subgraph "输入 (Input)"
        A[1分钟音频<br/>(32kHz)]
    end

    subgraph "阶段一：宏观兴趣区域检测 (Stage 1: Macro ROI Gating)"
        B[滑动窗口<br/>(5s窗长, 2.5s步长)] --> C{ECAPA-TDNN 模型}
        C --> D[筛选候选区域 (ROI)]
    end

    subgraph "阶段二：频率优化特征提取 (Stage 2: Freq-Optimized Feature Extraction)"
        E[对ROI计算<br/><b>超高频域分辨率</b><br/>线性频谱图]
    end

    subgraph "阶段三：U-Net频率定位 (Stage 3: U-Net Frequency Localization)"
        F{单一多类别 U-Net} --> G[生成多通道概率图]
        G --> H[连通域分析]
        H --> I[提取<b>精确频率</b>和<b>粗略时间</b><br/>(p_min_f, p_max_f, c_start_t, c_end_t)]
    end
    
    subgraph "阶段四：高精度时间定位 (Stage 4: High-Precision Temporal Localization)"
        J[带通滤波<br/>(使用 p_min_f, p_max_f)] --> K[计算信号包络<br/>(e.g., Hilbert Transform)]
        K --> L[阈值检测<br/>获取精确起止点]
    end

    subgraph "输出 (Output)"
        M[结构化鸟鸣事件列表<br/>(JSON)]
    end

    A --> B
    D --> E
    E --> F
    I --> J
    L --> M
```

---

## 3. 关键决策：应对时间-频率不确定性

任何基于傅里叶变换的分析都受不确定性原理的约束：`Δt * Δf ≥ 1 / (4π)`。这意味着我们无法用一个STFT同时获得任意高的时频分辨率。

*   **为达 ≤ 10 Hz 频率精度**: `n_fft ≥ 32000 / 10 = 3200`。我们必须选择 `n_fft = 4096`。
*   这导致STFT的分析窗口长达 `4096 / 32000 = 0.128s = 128ms`。

用一个128ms的“放大镜”去实现10ms的定位精度是不可行的。因此，本方案的核心思想是**任务解耦**:
1.  用一个**频率优化**的STFT（大`n_fft`）和U-Net来获得最准的**频率边界**。
2.  然后，在U-Net找到的频率带内，用另一种**时间优化**的方法（信号包络分析）来寻找最准的**时间边界**。

---

## 4. 详细工程方案

### 4.1. 阶段一：宏观区域兴趣度检测
此阶段保持不变，利用ECAPA-TDNN作为高效的“哨兵”来筛选候选区域（ROI）。

### 4.2. 阶段二：频率优化的时频谱特征提取

此阶段的目标是**频率精度最大化**。

1.  **STFT参数设计**:
    *   **采样率 (fs)**: 32000 Hz
    *   **FFT点数 (n_fft)**: **4096**。
        *   *理论支撑*: `Δf = 32000 / 4096 = 7.8125 Hz`，满足 `≤ 10 Hz` 的要求。
    *   **帧移 (hop_length)**: **320**。
        *   *理论支撑*: `Δt = 320 / 32000 = 0.01 s = 10 ms`。这确保了频谱图在时间轴上有足够密度的采样点，以进行后续处理。
    *   **窗口函数**: Hann窗或Hamming窗。

2.  **重要提示：计算成本**:
    *   相比之前`n_fft=2048`的方案，新的频谱图在频率轴上扩大了2倍，尺寸显著增大，会增加后续U-Net训练和推理的内存消耗与计算时间。

### 4.3. 阶段三：U-Net频率定位

此阶段使用U-Net在频率维度上进行精确分割，时间维度上提供粗略范围。

1.  **模型设计**: 采用与前版方案一致的单一、多类别U-Net，输入为上述高分辨率线性频谱图。
2.  **事件提取**:
    *   通过对U-Net输出的概率图进行阈值化和连通域分析，我们为每个检测到的事件提取出一个边界框。
    *   **关键输出**: 此阶段的输出是 `(precise_low_freq, precise_high_freq)` 和 `(coarse_start_time, coarse_end_time)`。频率是精确的，但时间是粗略的（受128ms分析窗口影响）。

### 4.4. 阶段四：高精度时间定位

这是新增的关键阶段，负责在时间维度上进行“精加工”，以达到10ms的精度要求。

对于从阶段三得到的每个候选事件：

1.  **音频切片**: 根据 `(coarse_start_time, coarse_end_time)`，并加入一些安全边际（如前后各加100ms），从原始ROI音频中提取出一段短音频。
2.  **带通滤波 (Band-pass Filtering)**: 使用阶段三得到的 `(precise_low_freq, precise_high_freq)` 对该音频切片进行带通滤波。这步至关重要，它能滤除带外噪声，极大地提升后续包络检测的信噪比和准确性。
3.  **计算信号包络 (Signal Envelope Calculation)**:
    *   计算滤波后信号的包络线，以获得其能量随时间的高分辨率变化。
    *   **推荐方法**: 使用**希尔伯特变换 (Hilbert Transform)** 计算解析信号，其模就是瞬时包络。此方法在理论上最为精确。
    *   *备选方法*: 计算短期均方根（RMS）能量，窗口大小设为极小值（如160个采样点，即5ms）。
4.  **精确边界检测 (Thresholding)**:
    *   在计算出的包络线上，通过一个动态阈值（如高于背景噪声均值若干分贝，或达到峰值能量的10%）来确定事件的精确起止点。
    *   从前向后搜索第一个超过阈值的点，作为 `precise_start_time`。
    *   从后向前搜索第一个超过阈值的点，作为 `precise_end_time`。
    *   这些时间点的精度直接取决于包络线的计算精度，可以轻松达到10ms甚至更高的要求。

### 4.5. 训练数据与鲁棒性策略

U-Net模型的性能高度依赖于训练数据的质量和数量。本节将详细阐述数据要求、标注流程，以及如何在有限的标注数据下实现强大的模型鲁棒性。

#### 4.5.1. 标注流程：从候选到真值

ECAPA-TDNN筛选出的5s音频仅仅是**候选**，要训练U-Net，我们必须通过以下步骤创建**训练真值 (Ground Truth)**：

1.  **人工标注**: 对于候选音频，鸟类专家需要使用音频标注工具（如Audacity、Raven Lite）在频谱图上为每个鸟鸣事件精确绘制**时频边界框 (Time-Frequency Bounding Box)**，即 `(start_time, end_time, low_freq, high_freq)`。这是整个项目中最关键、最需要投入人力的环节。
2.  **数据量建议**: 针对**每个物种**，建议从 **100-200个** 独立的、多样化的鸣叫事件标注开始。**多样性**（覆盖不同个体、背景噪声、录音条件）比单纯追求数量更重要。

#### 4.5.2. 小样本下的鲁棒性核心策略

面对标注数据有限的现实，我们的核心思想是**引入先验知识**并**最大化数据利用率**，而非让模型从零学习。

*   **策略一：迁移学习 (Transfer Learning) - 站在巨人的肩膀上**
    *   **实施方法**: 在初始化U-Net模型时，其编码器部分（下采样路径）不采用随机权重，而是加载在大型图像数据集（如 **ImageNet**）上预训练好的权重。
    *   **原理**: 图像和声谱图在底层特征（如边缘、纹理、形状）上具有共通性。利用预训练权重，模型从一开始就具备了强大的基础特征提取能力，只需在您的少量数据上进行微调（Fine-tuning），即可快速学会识别鸟鸣的特定模式。

*   **策略二：先进的数据增强 (Advanced Data Augmentation) - 性价比最高**
    *   我们通过在多个层面创造新的训练样本，来扩充数据集、提升模型泛化能力。
    *   **音频层面增强**:
        *   **噪声叠加 (Noise Overlay)**: 将已标注的鸟声音频，与数据集中其他时段的**真实背景噪声**进行随机混合，以模拟各种信噪比环境。
    *   **频谱图层面增强**:
        *   **SpecAugment**: 这是音频任务的**关键增强技术**。在训练期间，对输入的频谱图随机进行：
            *   **时间遮蔽 (Time Masking)**: 随机遮盖一小段连续的时间步。
            *   **频率遮蔽 (Frequency Masking)**: 随机遮盖一小段连续的频率通道。
        *   **原理**: SpecAugment迫使模型不能依赖于信号中脆弱、完整的特定模式，必须学会从不完整的信息中识别出关键特征，从而对噪声和部分遮挡具有极强的鲁棒性。

*   **策略三：半监督学习 (Semi-supervised Learning) - 放大标注价值**
    *   此策略旨在利用您手上大量未标注的5s音频片段。
    *   **实施流程（伪标签 Pseudo-Labeling）**:
        1.  使用您手头有限的人工标注数据，训练一个初始的U-Net模型。
        2.  将这个模型应用于所有未标注的5s候选音频，并进行预测。
        3.  筛选出模型预测置信度极高（如平均概率 > 0.95）的预测结果，将这些高可信度的预测视为“伪标签”。
        4.  将这些带有伪标签的数据加入到人工标注的训练集中。
        5.  在合并后的、更大的数据集上重新训练U-Net模型。
        6.  可选择性地重复2-5步，通过迭代实现“自学习”，逐步提升模型性能。

通过结合以上策略，您的模型将能更高效、更鲁棒地从有限的标注数据中进行学习，从而大幅提升最终定位的准确性和泛化能力。

---

## 5. 最终输出

系统最终输出一个结构化的JSON列表，其时频边界由两个解耦的阶段（阶段三和阶段四）共同确定：

```json
[
  {
    "species_id": "Black-capped Chickadee",
    "confidence": 0.92,
    "start_time_s": 15.211,
    "end_time_s": 15.583,
    "min_freq_hz": 3542.5,
    "max_freq_hz": 4210.9
  }
]
```
此输出的时频精度均满足设计要求，为后续分析提供了目前技术水平下非常精细的数据支持。
