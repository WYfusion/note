# 定义
![[Pasted image 20250610163057.png|800]]
# 性质
![[Pasted image 20250610163111.png|800]]
![[Pasted image 20250610163125.png|800]]
![[Pasted image 20250610163428.png|800]]
![[Pasted image 20250610163437.png|800]]





### 柯西点（Cauchy Point）的定义与推导
#### 一、背景与直观理解
柯西点是优化算法中**信赖域方法（Trust Region Methods）**的核心概念之一，用于求解无约束优化问题的**局部近似子问题**。其核心思想是：在当前点附近的一个有限区域（信赖域）内，沿着**最速下降方向**（负梯度方向）寻找使目标函数的二次近似模型最小化的点。
通俗地说，假设你在夜晚爬山，只能看清脚下半径为$\Delta$的范围（信赖域），柯西点就是你在这个范围内沿着 “最陡下坡方向”（负梯度）能走到的最低点。它是信赖域子问题的一个**解析解**，计算简单且具有明确的几何意义。
#### 二、严谨定义
考虑无约束优化问题：$\min_{x} \, f(x)$ 在当前点$x^k$处，构建信赖域子问题，用二次函数近似目标函数$f(x)$：$\min_{d} \, m_k(d) = f(x^k) + \nabla f(x^k)^T d + \frac{1}{2} d^T B_k d \quad \text{约束条件：} \quad \|d\| \leq \Delta_k$ 其中：
- d 是搜索方向，$\Delta_k > 0$ 是信赖域半径，$B_k$ 是海森矩阵（或其近似）。
**柯西点**定义为：当$B_k = \sigma_k I$（$\sigma_k$为标量，I为单位矩阵）时，信赖域子问题沿**最速下降方向**的极小点。特别地，当$\sigma_k = 0$（即忽略二次项）时，柯西点退化为**一阶近似解**，此时仅考虑梯度方向。
#### 三、推导过程
##### 1. 设定搜索方向为最速下降方向
最速下降方向为负梯度方向，即：$d = -t \frac{\nabla f(x^k)}{\|\nabla f(x^k)\|}, \quad t \geq 0$ 其中t是步长，满足信赖域约束$\|d\| \leq \Delta_k$，即$t \leq \Delta_k$。
##### 2. 将搜索方向代入子问题模型
令$g_k = \nabla f(x^k)$，则模型函数$m_k(d)$可写为：$m_k(t) = f(x^k) + g_k^T \left(-t \frac{g_k}{\|g_k\|}\right) + \frac{1}{2} \left(-t \frac{g_k}{\|g_k\|}\right)^T B_k \left(-t \frac{g_k}{\|g_k\|}\right)$ 
简化后：$m_k(t) = f(x^k) - t \|g_k\| + \frac{1}{2} t^2 \cdot \frac{g_k^T B_k g_k}{\|g_k\|^2}$ 这是关于t的一元二次函数，记为：$m_k(t) = a + b t + c t^2, \quad \text{其中：} \quad a = f(x^k), \, b = -\|g_k\|, \, c = \frac{g_k^T B_k g_k}{2\|g_k\|^2}$
##### 3. 求解单变量优化问题
分两种情况讨论：
###### 情况 1：$c = 0$（即$B_k = 0$，一阶近似）
此时模型退化为线性函数：$m_k(t) = f(x^k) - t \|g_k\|$ 在约束$t \leq \Delta_k$下，最小值出现在最大步长$t = \Delta_k$处，对应解：$d_{\text{Cauchy}} = -\Delta_k \frac{g_k}{\|g_k\|}$
###### 情况 2：$c > 0$（正定二次项）
二次函数开口向上，极小值点为：$t^* = \frac{\|g_k\|}{2c} = \frac{\|g_k\|^3}{g_k^T B_k g_k}$ 需判断$t^*$是否在信赖域内：
- 若$t^* \leq \Delta_k$：极小值在内部点$t = t^*$处，对应解：$d_{\text{Cauchy}} = -t^* \frac{g_k}{\|g_k\|} = -\frac{\|g_k\|^2}{g_k^T B_k g_k} g_k$
- 若$t^* > \Delta_k$：极小值在边界$t = \Delta_k$处，解为：$d_{\text{Cauchy}} = -\Delta_k \frac{g_k}{\|g_k\|}$
##### 4. 统一表达式
引入符号$\sigma_k = \frac{g_k^T B_k g_k}{\|g_k\|^2}$（可理解为沿梯度方向的曲率），则最优步长为：$t_{\text{opt}} = \min\left(\frac{\|g_k\|}{\sigma_k}, \Delta_k\right)$ 因此，柯西点的搜索方向为：$d_{\text{Cauchy}} = -t_{\text{opt}} \frac{g_k}{\|g_k\|} = -\min\left(\frac{\|g_k\|}{\sigma_k}, \Delta_k\right) \frac{g_k}{\|g_k\|}$ 进一步简化为：$d_{\text{Cauchy}} = -\frac{\min\left(\|g_k\|, \sigma_k \Delta_k\right)}{\sigma_k} g_k \quad (\text{当} \sigma_k \neq 0)$
#### 四、关键性质与意义
1. **一阶最优性**： 柯西点满足信赖域子问题的**KKT 条件**（Karush-Kuhn-Tucker 条件），即在约束边界或内部取得极值。
2. **计算高效**： 无需求解高维线性方程组，只需沿梯度方向进行一维搜索，适合大规模问题。
3. **信赖域方法的基准**： 在信赖域算法中，常将柯西点作为初始解或近似解，与牛顿型解（如精确子问题解）对比，判断是否需要调整信赖域半径。
4. **收敛性保证**： 作为信赖域方法的基础，柯西点的存在性确保了算法在合理假设下的收敛性（如梯度范数趋于零）。
#### 五、与最速下降法的区别
- **最速下降法**：无步长约束，沿负梯度方向无限搜索（步长由线搜索确定）。
- **柯西点**：受信赖域半径限制，步长最大为$\Delta_k$，是**带约束的最速下降解**。
本质上，柯西点是最速下降法在信赖域框架下的 “局部化” 版本，平衡了搜索方向与步长限制。
#### 六、总结
**柯西点**是信赖域子问题中沿最速下降方向的解析解，通过将高维优化问题转化为一维搜索，高效地提供了一个可行的下降方向。其核心推导基于**二次模型近似**和**约束优化理论**，是理解信赖域方法（如 Steihaug-Toint 算法）的基础。在实际应用中，柯西点常作为优化算法的初始步骤或基准解，兼具理论严谨性与计算高效性。

