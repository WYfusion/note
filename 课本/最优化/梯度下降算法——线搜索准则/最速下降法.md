最速下降法是无约束优化中最基础的迭代算法，其原理基于**梯度的方向性质**，具体如下：
### 1. **梯度与函数变化的关系**
- 对于多元函数 $f(\boldsymbol{x})$，梯度 $\nabla f(\boldsymbol{x}) = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n} \right)^T$ 表示函数在点 $\boldsymbol{x}$ 处的**最速上升方向**（函数值增长最快的方向）。
- 负梯度方向 $-\nabla f(\boldsymbol{x})$ 则是**最速下降方向**（函数值下降最快的方向），即：$f(\boldsymbol{x} + \boldsymbol{d}) \approx f(\boldsymbol{x}) + \nabla f(\boldsymbol{x})^T \boldsymbol{d},$ 当 $\boldsymbol{d} = -\alpha \nabla f(\boldsymbol{x})$（$\alpha > 0$ 为步长）时，$\nabla f(\boldsymbol{x})^T \boldsymbol{d} = -\alpha \|\nabla f(\boldsymbol{x})\|^2 \leq 0$，确保函数值下降（$\alpha = 0$ 时不变，$\alpha > 0$ 时严格下降）。
### 2. **迭代公式**
- 第 k 步迭代为：$\boldsymbol{x}^{(k+1)} = \boldsymbol{x}^{(k)} - \alpha^{(k)} \nabla f(\boldsymbol{x}^{(k)}),$ 其中 $\alpha^{(k)}$ 是**步长**，通过一维搜索（如精确线搜索 $\alpha^{(k)} = \arg\min_{\alpha \geq 0} f(\boldsymbol{x}^{(k)} - \alpha \nabla f(\boldsymbol{x}^{(k)}))$）确定，使当前方向上的函数值下降最多。
### 3. **数学推导：为何负梯度是最速下降方向？**
- 固定步长范数 $\|\boldsymbol{d}\| = \alpha$，最小化 $\nabla f(\boldsymbol{x})^T \boldsymbol{d}$。由向量内积公式：$\nabla f(\boldsymbol{x})^T \boldsymbol{d} = \|\nabla f(\boldsymbol{x})\| \|\boldsymbol{d}\| \cos\theta,$ 当 $\theta = \pi$（$\boldsymbol{d}$ 与 $\nabla f(\boldsymbol{x})$ 反向，即 $\boldsymbol{d} = -\nabla f(\boldsymbol{x})$ 方向）时，$\cos\theta = -1$，内积最小，函数值下降最快。
### 4. **收敛性与特点**
- **收敛性**：对凸函数，最速下降法全局收敛（逐步逼近极小值点）；对非凸函数，可能收敛到局部极小值。
- **缺点**：收敛速度慢（尤其是接近极小值时，相邻搜索方向正交，形成 “之字形” 迭代，如二次函数 $f(\boldsymbol{x}) = \frac{1}{2}\boldsymbol{x}^T Q \boldsymbol{x} + \boldsymbol{b}^T \boldsymbol{x} + c$，相邻梯度方向正交 $\nabla f(\boldsymbol{x}^{(k)})^T \nabla f(\boldsymbol{x}^{(k+1)}) = 0$）。
- **优点**：每步计算量小（仅需梯度），适用于初始迭代或作为其他算法的子步骤。
### 5. **应用示例**
给定函数 $f(\boldsymbol{x}) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$，最速下降方向为该点的负梯度方向。首先求梯度：
1. 计算偏导数：
    - 对 $x_1$ 的偏导数： $\frac{\partial f(x)}{\partial x_1} = -400x_1(x_2 - x_1^2) - 2(1 - x_1)$
    - 对 $x_2$ 的偏导数： $\frac{\partial f(x)}{\partial x_2} = 200(x_2 - x_1^2)$
2. 代入点 $\boldsymbol{x}^{(1)} = \begin{bmatrix} \frac{3}{2} \\ 1 \end{bmatrix}$：
    - 计算 $x_2 - x_1^2 = 1 - \left(\frac{3}{2}\right)^2 = -\frac{5}{4}$。
    - 对 $x_1$ 的偏导数： $-400 \cdot \frac{3}{2} \cdot \left(-\frac{5}{4}\right) - 2\left(1 - \frac{3}{2}\right) = 750 + 1 = 751$
    - 对 $x_2$ 的偏导数： $200 \cdot \left(-\frac{5}{4}\right) = -250$
3. 梯度与最速下降方向：
    - 梯度 $\nabla f(\boldsymbol{x}^{(1)}) = \begin{bmatrix} 751 \\ -250 \end{bmatrix}$，
    - 最速下降方向为负梯度： $-\nabla f(\boldsymbol{x}^{(1)}) = \begin{bmatrix} -751 \\ 250 \end{bmatrix}$
**答案**：最速下降方向为 $\begin{bmatrix} -751 \\ 250 \end{bmatrix}$。
- 计算当前点梯度 $\nabla f(\boldsymbol{x}^{(1)})$，取负得到最速下降方向 $-\nabla f(\boldsymbol{x}^{(1)})$，后续迭代沿此方向更新点（结合步长计算）。
### 总结
最速下降法通过**负梯度方向**逐次迭代，利用梯度的局部最速下降性质，逐步逼近函数极小值点。其原理简洁，是理解优化算法的基石，尽管实际中常需结合加速技巧（如共轭梯度法、牛顿法等），但核心思想始终是**沿负梯度方向搜索**。