### 无约束可微优化算法
![[Pasted image 20250609201352.png]]

#### 1. 核心思想
- **线搜索（Line Search）**： 每次迭代沿**下降方向**（如负梯度、牛顿方向）移动，通过**步长准则**（如精确 / 非精确线搜索）确定移动距离，逐步逼近极小点。
    - 步骤：
        1. **方向确定**：选择使函数值下降的方向（如 $d^k$ 满足 $\nabla f(x^k)^T d^k < 0$）。
        2. **步长更新**：通过 $\alpha_k$ 调整步长（如 Armijo 准则保证足够下降），更新 $x^{k+1} = x^k + \alpha_k d^k$。
- **信赖域（Trust Region）**： 在迭代点 $x^k$ 周围定义**信赖域（半径 $\Delta_k$）**，用**二次模型**（如 $(g^k)^T d + \frac{1}{2}d^T B d$，$g^k$ 为梯度，B 为 Hessian 或近似矩阵）近似原函数，求解子问题 $\min_d \text{二次模型}, \, \|d\| \leq \Delta_k$ 得到方向 $d^k$。通过**下降性检验**（实际与模型下降量的比值）更新 $x^{k+1}$ 和信赖域半径 $\Delta_k$。
    - **步骤**：
        1. **子问题求解**：在信赖域内找最优方向 $d^k$（可能在边界 $\|d\| = \Delta_k$ 或内部，依 B 的正定性）。
        2. **接受 / 拒绝新点**：若 $z^k = x^k + d^k$ 使 $f(z^k) < f(x^k)$，则接受 $z^k$ 并扩大 $\Delta_k$；否则拒绝，缩小 $\Delta_k$ 重新求解。
#### 2. 证明步骤（收敛性）
- **线搜索**：
    - 对凸函数，证明 $\|\nabla f(x^k)\| \to 0$（如最速下降法的线性收敛）。
    - 对一般函数，证明函数值序列 $\{f(x^k)\}$ 下降且有下界，故收敛到临界点（需满足步长准则的**充分下降条件**）。
- **信赖域**：
    - 证明信赖域半径 $\Delta_k$ 不会趋于零（否则无法继续下降），且子问题解 $d^k$ 满足 $f(x^k + d^k) \leq f(x^k) - \epsilon$（$\epsilon > 0$），从而 $\{f(x^k)\}$ 收敛到极小值（需分析子问题的**负曲率处理**和半径更新策略）。
#### 3. 作用
- **线搜索**：
    - **简单高效**：计算量小，适用于低维或梯度信息易获取的问题（如最速下降法、牛顿法的基础框架）。
    - **灵活性**：步长可根据函数特性调整（如陡峭处小步，平缓处大步）。
- **信赖域**：
    - **鲁棒性强**：通过信赖域控制步长，避免牛顿法在非二次函数上的 “步长过大” 问题，适合**非线性强**的函数（如高维优化、非凸问题）。
    - **全局收敛**：即使初始点远离极小点，也能通过调整信赖域半径逐步逼近（如结合 BFGS 近似 Hessian 的拟牛顿信赖域方法）。
#### 4. 注意事项与细节
- **线搜索**：
    - **方向有效性**：确保 $d^k$ 是下降方向（$\nabla f(x^k)^T d^k < 0$），否则算法可能发散。
    - **步长准则**：非精确线搜索（如 Armijo 准则）需合理选择参数（如松弛因子 $\sigma \in (0, 1)$），避免步长过小（收敛慢）或过大（不满足下降条件）。
- **信赖域**：
    - **子问题求解**：
        - 当 B 正定时，子问题解可能在边界（用**投影法**求解，如 Cauchy 点或 Dogleg 法）；
        - 当 B 不定时，需处理**负曲率方向**（确保子问题有解，避免模型无下界）。
    - **半径更新**：
        - 比值 $r_k = \frac{f(x^k) - f(z^k)}{f(x^k) - m_k(d^k)}$（$m_k$ 为模型值），若 $r_k \approx 1$（模型准确），扩大 $\Delta_k$；若 $r_k \approx 0$（模型不准），缩小 $\Delta_k$，保证算法**自适应调整步长范围**。
#### 5. 通俗类比
- **线搜索**：像 “盲人摸路”，每次沿一个方向走，走多远看脚下路的 “陡峭程度”（步长准则），适合熟悉地形（函数光滑）的情况。
- **信赖域**：像 “戴着眼罩探索”，先定一个 “探索范围”（信赖域），在范围内找最好的方向，再看这个方向是否真的让自己更接近目标（下降性检验），范围大小根据实际效果调整，适合地形复杂（函数非线性强）的情况。

### 总结
- **线搜索**：简单直接，依赖方向和步长的合理选择，适合光滑函数的优化。
- **信赖域**：更稳健，通过模型近似和半径调整处理复杂函数，保证全局收敛。
- 两者均为无约束优化的经典框架，实际应用中需根据函数特性（如凸性、光滑性、维数）选择方法，或结合使用（如信赖域内的线搜索子问题求解）。