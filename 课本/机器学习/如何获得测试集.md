测试集用于度量模型**对未知数据的泛化能力**
1. 留出法 hold-out
2. 交叉验证法  cross validation
3. 自助法  bootstrap
#### 1. 留出法（Hold-out）
- **原理**： 直接将数据集划分为**训练集**（T）和**验证集**（V），两者互斥。常见比例为 **7:3** 或 **8:2**，划分时需保持数据分布一致（如分类任务用**分层抽样**，确保类别比例相同）。
- **步骤**：
    1. 随机划分数据（如`train_test_split`函数）。
    2. 训练集训练模型，验证集评估性能（如准确率、R²）。
- **优点**：简单高效，适合大规模数据（如百万级样本），快速验证模型。
- **缺点**：结果不稳定（不同划分影响大），数据浪费（验证集未参与训练，小数据时训练集不足）。
- **应用**：数据充足时的初步评估（如探索性分析、快速模型筛选）。
#### 2. 交叉验证法（Cross Validation, CV）
- **原理**： 将数据分为 **K 个折（fold）**，每次用 **K-1 折训练**，**1 折验证**，重复 K 次，取平均结果。常见 K=5、10（如 10 折 CV，每个样本参与训练 9 次、验证 1 次）。
- **步骤（10 折为例）**：
    1. 随机分 10 份，轮流用 9 份训练、1 份验证，共 10 次。
    2. 计算平均评估结果（如平均准确率）。
- **优点**：评估稳定（充分利用数据，减少划分随机性），数据利用率高（适合小数据，如 < 10,000 样本）。
- **缺点**：计算成本高（训练 K 次模型，时间为留出法的 K 倍）。
- **扩展（留一法，LOO）**： 特殊情况（K=m，m 为样本数），每次留 1 个样本验证，训练 m-1 个样本。数据利用率 100%（除 1 个验证），但计算量极大（仅适合 m<1000 的小数据）。
- **应用**：模型调参（如超参数优化，确保泛化能力）、小数据场景（如医学图像、生物信息学）。
- **全数据覆盖**：每个样本**恰好作为验证集一次**（K 次验证集的并集为全数据集），训练集覆盖**K-1 次**（每次训练使用不同的 K-1 个子集，无重复）。
- **独立训练**：每次训练（共 K 次）是**完整的模型训练过程**（从初始化到参数优化），使用不同的训练数据（子集不同，数据分布略有差异），生成**K 组独立的模型参数**（如决策树的分裂规则、回归模型的权重）。
- **K 折 CV 的输出是 “性能指标”，而非 “模型参数”**：它的价值在于评估和调参，而非生成可用模型。
#### 3. 自助法（Bootstrap）
- **原理**： 通过**有放回抽样**生成训练集 $D'$（约 63.2% 原始样本，36.8% 未被抽到作为验证集 $D \setminus D'$）。
- **步骤**：
    1. 自助采样 m 次（有放回），生成训练集 $D'$。
    2. 验证集为未被抽到的样本，训练模型并评估，重复多次（如 1000 次）取平均。
- **优点**：数据利用最大化（训练集大小与原始数据相同，适合极小数据，如 m<100），增强模型鲁棒性（通过多次采样）。
- **缺点**：改变数据分布（训练集含重复样本，验证集为袋外数据，与真实场景有偏差），计算复杂（多次采样训练）。
- **应用**：极小数据（如 m<50）、集成学习（如随机森林的 Bagging，生成多样化训练集）。
#### 4. 对比与选择

|**方法**|**优点**|**缺点**|**适用场景**|
|---|---|---|---|
|**留出法**|简单、高效、直观|结果不稳定、数据浪费|大规模数据（>10 万样本），快速验证|
|**交叉验证**|评估稳定、数据利用率高|计算成本高|模型调参、小数据（1 万～10 万样本）|
|**自助法**|数据利用最大化、鲁棒性强|分布偏差、计算复杂|极小数据（<100 样本）、集成学习基模型|

### 总结
- **留出法**：快速入门，适合数据充足时的初步评估。
- **交叉验证**：模型调参的 “黄金标准”，确保评估稳定，尤其在小数据和超参数优化中。
- **自助法**：极端数据稀缺时的选择，或作为集成学习的基础（如 Bagging）。

**选择建议**：
- 数据量 > 10 万：留出法（7:3 划分，单次即可）。
- 数据量 1 万～10 万：交叉验证（5~10 折，平衡计算与稳定性）。
- 数据量 < 1 万：交叉验证（10 折或留一法，最大化数据利用）。
- 数据量 < 100：自助法（或结合交叉验证，如 5 折自助 CV）。