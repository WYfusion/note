**核心思想**：  
将神经网络的前向传播视为连续动态系统的演化过程，通过常微分方程（ODE）建模隐藏状态的连续变化。传统神经网络（如ResNet）的残差层可视为离散时间步的近似，而神经ODE将其推广到连续时间域，用数值积分代替离散层堆叠。

#### **数学细节**

1. **状态演化方程**：  
    隐藏状态 $z(t)$ 的导数由神经网络 f$_\theta$​ 定义：        $$\frac{dz(t)}{dt}=f_\theta(z(t),t)$$
    最终输出通过数值积分求解初始值问题（IVP）得到：   $$z(t_1)=z(t_0)+\int_{t_0}^{t_1}f_\theta(z(t),t)dt$$
2. **反向传播优化**：
    - 传统反向传播对多层网络内存消耗大（需存储每层激活值）。
    - 神经ODE采用**伴随方法**（Adjoint Method），通过求解伴随状态ODE反向计算梯度，仅需常数内存：        $$\frac{dL}{d\theta}=-\int_{t_1}^{t_0}a(t)^T\frac{\partial f_\theta}{\partial\theta}dt,\quad a(t)=\frac{dL}{dz(t)}$$
        - 其中 $a(t)$ 为伴随状态，与正向ODE联合求解。
3.  **优势与挑战**
    - **优势**：
        - 内存高效：适合实时系统或长序列建模（如视频、物理仿真）。
        - 连续概率建模：基于归一化流（Normalizing Flow）构建连续可逆变换（如FFJORD）。
    - **挑战**：
        - 计算代价：自适应ODE求解器可能引入计算延迟。
        - 数值稳定性：复杂动态易导致积分发散，需设计鲁棒的 $f_\theta$。