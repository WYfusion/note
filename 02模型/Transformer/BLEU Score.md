BLEU（Bilingual Evaluation Understudy）是一种广泛用于*评估***机器翻译或文本生成任务质量**的**自动评估指标**，尤其在seq2seq模型（如机器翻译、文本摘要、对话生成等）的测试阶段被广泛使用。它通过比较***模型生成的文本***（**候选文本**）与一个或多个***人工标注的高质量文本***（**参考文本**）之间的相似性来给出评分。
也就是说BLEU Score被用于**输出是明确的字符时**。

---

## **BLEU Score 的核心思想**
1. **n-gram 匹配**：计算候选文本与参考文本中 n-gram（连续的 n 个词）的重合程度。
2. **精度（Precision）修正**：对短文本生成的惩罚机制（避免过短的生成结果得分虚高）。
3. **几何平均**：综合多个 n-gram（通常取 1-gram 到 4-gram）的匹配结果。

---

### **BLEU 的计算步骤**
#n-gram
**n代表连续的n个词的组合**。"n"可以是1、2、3，或者更高。

- $1-gram$：也称为unigram，是指单个的词语。例如，在句子 "我喜欢学习自然语言处理。" 中的$1-gram$为：["我", "喜欢", "学习", "自然语言处理", "。"]  
- $2-gram$：也称为bigram，是指两个连续的词语组合。例如，在句子 "我喜欢学习自然语言处理。" 中的$2-gram$为：["我喜欢", "喜欢学习", "学习自然语言处理", "自然语言处理。"]  
- $3-gram$：也称为trigram，是指三个连续的词语组合。例如，在句子 "我喜欢学习自然语言处理。" 中的$3-gram$为：["我喜欢学习", "喜欢学习自然语言处理", "学习自然语言处理。"]

- $n-gram$在自然语言处理中是一种常用的技术，特别在机器翻译、文本摘要和语言模型等任务中广泛使用。使用$n-gram$**可以捕捉一定长度的上下文信息**，有助于更好地理解文本和评估翻译质量。例如，在机器翻译中，使用n-gram可以帮助评估系统生成的翻译与参考翻译之间的相似程度。

1. **n-gram 匹配**：
常规的n-gram匹配：将系统生成的翻译中的**匹配参考文本中n-gram数除以系统生成的总n-gram数**。
缺陷在于若候选文本中反复重复无意义的与参考文本中匹配的n-gram时，分数会虚高。

- 修正n-gram 匹配精度：
    - 其核心思想是：对于候选文本中的每个 n-gram，其匹配次数不能超过参考文本中该 n-gram 的最大出现次数。
        - 对每个 $n-gram$（如 $1-gram、2-gram、3-gram、4-gram$），统计候选文本中的每个 $n-gram$ 在参考文本中出现的次数。
        - 为避免重复匹配（比如，候选文本里某个词出现多次，但参考文本里可能只出现一次，这时候如果直接计算精度的话，就会高估匹配次数，导致分数虚高。所以修正精度就是用来限制每个n-gram的计数不超过参考中的最大次数），**n-gram 匹配**公式为：$$
    修正精度 = \frac{\sum\limits_{\text{n-gram} \in \text{候选文本}} \min(\text{候选中n-gram计数}, \text{参考中n-gram最大计数})}{\sum\limits_{\text{n-gram} \in \text{候选文本}} \text{候选中n-gram计数}}
    $$
        - 计算 $1-gram、2-gram、3-gram、4-gram$ 的匹配修正精度。

2. **几何平均**：
    - 将 $1-gram$ 到 $4-gram$ 的修正精度取对数后求平均：$$\text{平均精度}=\exp\left(\frac{1}{4}\sum_{n=1}^4\log p_n\right)$$        （其中 $p_n$​ 是第 $n-gram$ 的修正精度）
        
3. **简短惩罚（Brevity Penalty, BP）**：
    - 如果候选文本长度（$c$）小于参考文本的最短长度（$r$），则施加惩罚：$$BP=\begin{cases}1&\mathrm{if}\ \ c>r\\e^{(1-r/c)}&\mathrm{if}\ \ c\leq r&\end{cases}$$
    - 防止过短的生成结果得分过高。
        
4. **最终 BLEU 分数**：
    $$\mathrm{BLEU}=BP\cdot\exp\left(\sum_{n=1}^Nw_n\log p_n\right)$$
    通常取 $N=4$（即 4-gram），且各权重 $w_n$​ 相等（即 $w_n​=1/4$）。
    

---

### **BLEU 的特点**

1. **优点**：
    - 自动化、计算高效，适合大规模评估。
    - 与人工评价相关性较高（尤其在机器翻译任务中）。
    - 广泛应用于学术界和工业界。

2. **局限性**：
    - 无法直接衡量语义相似性（仅基于词重叠）。
    - 对同义词或语义相同但表达不同的句子不敏感。
    - 短文本得分可能不稳定（需依赖简短惩罚）。

---

### **在 seq2seq 模型中的应用**
在测试阶段，模型生成的文本会与人工标注的参考文本对比，计算 BLEU 分数。例如:
- **机器翻译**：将英文句子翻译为中文后，与专业翻译结果对比。
- **文本摘要**：生成的摘要与人工撰写的参考摘要对比。
---

### **注意事项**
- BLEU 通常以百分比形式表示（如 BLEU-4=0.35 或 百分比35），但分数本身没有绝对意义，需与基线模型对比。
- 若任务不依赖严格词序（如对话生成），BLEU 可能不够准确，需结合其他指标（如 ROUGE、METEOR）。