> [!tip]
> transformer是一个Sequence-to-sequence (Seq2seq)，（序列-->序列）的模型
##### **训练过程** 
**Teacher Forcing**：
在训练过程中会将训练集的序列送进模型中，模型会学习实现训练输入的序列也可以输出这个序列所需要的权重参数。训练时常用交叉损失函数。评估时常用

面临的问题在于实际使用时面对的是新的没见过的seq，因此就需要在新的输入传入时学习新的东西。

### 复制机制
在新的对话中看到名字、不懂的问题时，会返回该部分，只需复制关键的就行。

### 引导注意力机制Guided Attention
**Guided Attention（引导注意力）** 是一种在深度学习模型中，通过引入外部约束或先验知识来引导注意力机制的方法。它的核心目标是**强制或鼓励模型在训练过程中关注输入数据的特定区域或模式**，从而提升模型的可控性、稳定性或任务性能。

传统的注意力机制（如Soft Attention）允许模型动态地选择输入中的重要部分，但其学习过程通常是完全数据驱动的。这可能导致以下问题：
- **注意力发散**：模型可能关注无关区域（例如在语音合成中，注意力跳跃导致重复发音）。
- **对齐不稳定**：在序列到序列任务（如机器翻译、语音合成）中，注意力权重可能无法正确对齐输入和输出序列。
- **缺乏先验知识**：人类对任务的理解（如语音中时序单调性、图像中的空间局部性）未被显式利用。
**Guided Attention通过引入先验约束，解决上述问题**。

###### **核心思想**
在注意力计算中**显式加入约束条件**，例如：
- **单调性**：在语音合成中，强制注意力权重随时间单调递增。
- **局部性**：在图像生成中，限制注意力仅关注输入图像的局部区域。
- **对齐方向性**：在机器翻译中，鼓励目标词关注源语言中对应的位置。
这些约束通过**修改注意力权重计算**或**在损失函数中添加惩罚项**实现。

## Beam Search
每次只挑分数最大的路径走，这样可能会导致遗失当前不好但未来会更好的选择。
![[Pasted image 20250315223450.png|600]]
Beam Search的作用就是搜查一个尽可能好，但可能不是很精准的目标路径方案。有时候没用，但有时候有用。
这个技术适合对于一个问题只有唯一可能的解时比较有用。
对于不确定性的是不太适合的，当然也可以添加一些随机性noise(**测试的时候**)反而会效果好一点。


###  Scheduled Sampling

