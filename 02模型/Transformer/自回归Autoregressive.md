需要有$Start$和$End$，只在$Start$和$End$的控制范围内输出seq。

**核心机制**：
采用“链式生成”，每一步预测依赖前序所有输出。例如，在机器翻译中，模型输入为“|start | 你|”，预测“好”；输入更新为“|start| 你| 好 |”，预测“世”，依此类推。
**掩码自注意力**（Masked Self-Attention）是关键，确保解码时仅关注历史信息

**适用场景**：质量优先于速度的机器翻译、自然语言生成(NLG)。自回归**天然适配***因果*语言建模。

![[Pasted image 20250315174643.png|300]]