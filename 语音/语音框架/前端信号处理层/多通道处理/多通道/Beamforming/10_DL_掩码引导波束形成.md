# 掩码引导波束形成

## 1. 概述

**掩码引导波束形成 (Mask-Guided Beamforming)** 结合了深度学习的掩码估计能力和传统波束形成的物理约束，是一种混合方法。

### 1.1 核心思想

```
多通道输入
    ↓
[神经网络]
    ↓
时频掩码 (M_s, M_n)
    ↓
[掩码引导协方差估计]
    ↓
[传统波束形成器]
    ↓
增强信号
```

**优势**：
- 神经网络：强大的模式识别能力
- 传统波束形成：物理约束和可解释性

### 1.2 与纯神经网络的对比

| 特性 | 纯神经网络 | 掩码引导BF |
|------|------------|------------|
| 数据需求 | 大 | 中 |
| 可解释性 | 差 | 好 |
| 物理约束 | 无 | 有 |
| 泛化能力 | 中 | 好 |

---

## 2. 数学模型

### 2.1 信号模型

频域多通道信号：

$$\mathbf{X}(f,t) = \mathbf{d}(f)S(f,t) + \mathbf{N}(f,t)$$

其中：
- $\mathbf{X}(f,t) \in \mathbb{C}^P$：观测信号
- $\mathbf{d}(f) \in \mathbb{C}^P$：导向矢量
- $S(f,t)$：目标信号
- $\mathbf{N}(f,t)$：噪声

### 2.2 掩码定义

**理想比值掩码 (IRM)**：

$$M_S(f,t) = \frac{|S(f,t)|^2}{|S(f,t)|^2 + |N(f,t)|^2}$$

$$M_N(f,t) = \frac{|N(f,t)|^2}{|S(f,t)|^2 + |N(f,t)|^2} = 1 - M_S(f,t)$$

**理想二值掩码 (IBM)**：

$$M_S(f,t) = \begin{cases}
1, & \text{if } \text{SNR}(f,t) > \theta \\
0, & \text{otherwise}
\end{cases}$$

### 2.3 掩码引导协方差估计

**信号协方差矩阵**：

$$\hat{\mathbf{R}}_S(f) = \frac{\sum_t M_S(f,t) \mathbf{X}(f,t)\mathbf{X}^H(f,t)}{\sum_t M_S(f,t)}$$

**噪声协方差矩阵**：

$$\hat{\mathbf{R}}_N(f) = \frac{\sum_t M_N(f,t) \mathbf{X}(f,t)\mathbf{X}^H(f,t)}{\sum_t M_N(f,t)}$$

**物理意义**：
- 掩码作为**软权重**，选择信号/噪声主导的时频点
- 相比硬判决（VAD），软掩码更鲁棒

### 2.4 波束形成权重

使用估计的协方差矩阵计算MVDR权重：

$$\mathbf{w}(f) = \frac{\hat{\mathbf{R}}_N^{-1}(f) \mathbf{d}(f)}{\mathbf{d}^H(f) \hat{\mathbf{R}}_N^{-1}(f) \mathbf{d}(f)}$$

**输出**：

$$Y(f,t) = \mathbf{w}^H(f) \mathbf{X}(f,t)$$

---

## 3. 神经网络掩码估计

### 3.1 输入特征

**多通道特征**：
1. **幅度谱**：$|X_p(f,t)|, p=1,\ldots,P$
2. **相位差 (IPD)**：$\angle X_i(f,t) - \angle X_j(f,t)$
3. **GCC-PHAT**：广义互相关
4. **协方差特征**：$\text{Re}(\mathbf{R}_X), \text{Im}(\mathbf{R}_X)$

**特征拼接**：

$$\mathbf{F}(f,t) = [\mathbf{|X|}(f,t), \mathbf{IPD}(f,t), \ldots] \in \mathbb{R}^D$$

### 3.2 网络架构

**LSTM网络**：

```python
class MaskEstimationNet(nn.Module):
    def __init__(self, n_fft, n_mics):
        super().__init__()
        self.n_freq = n_fft // 2 + 1
        self.n_mics = n_mics
        
        # 输入维度：幅度谱 + IPD
        input_dim = n_mics + n_mics * (n_mics - 1) // 2
        
        # LSTM层
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=512,
            num_layers=3,
            batch_first=True,
            bidirectional=True
        )
        
        # 输出层
        self.fc = nn.Sequential(
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 2),  # 语音掩码 + 噪声掩码
            nn.Sigmoid()
        )
    
    def forward(self, X_mag, IPD):
        # X_mag: [B, T, F, M]
        # IPD: [B, T, F, M*(M-1)/2]
        B, T, F, M = X_mag.shape
        
        # 拼接特征
        features = torch.cat([X_mag, IPD], dim=-1)
        
        # 频点独立处理
        masks = []
        for f in range(F):
            feat_f = features[:, :, f, :]  # [B, T, D]
            h, _ = self.lstm(feat_f)
            mask_f = self.fc(h)  # [B, T, 2]
            masks.append(mask_f)
        
        masks = torch.stack(masks, dim=2)  # [B, T, F, 2]
        
        return masks[:, :, :, 0], masks[:, :, :, 1]
```

### 3.3 训练目标

**损失函数**：

$$\mathcal{L} = \mathcal{L}_{\text{mask}} + \lambda \mathcal{L}_{\text{output}}$$

**掩码损失**：

$$\mathcal{L}_{\text{mask}} = \frac{1}{TF}\sum_{t,f} \left[(M_S^{\text{pred}}(f,t) - M_S^{\text{true}}(f,t))^2 + (M_N^{\text{pred}}(f,t) - M_N^{\text{true}}(f,t))^2\right]$$

**输出信号损失**：

$$\mathcal{L}_{\text{output}} = \frac{1}{TF}\sum_{t,f} |Y(f,t) - S(f,t)|^2$$

---

## 4. 改进方法

### 4.1 复数掩码

**动机**：IRM只估计幅度，忽略相位信息

**复数比值掩码 (CRM)**：

$$M_C(f,t) = \frac{S(f,t)}{X_{\text{ref}}(f,t)} = M_R(f,t) + jM_I(f,t)$$

**网络输出**：实部和虚部

```python
self.fc = nn.Linear(512, 2)  # 实部 + 虚部（无激活函数）
```

**应用**：

$$\hat{S}(f,t) = M_C(f,t) \cdot X_{\text{ref}}(f,t)$$

### 4.2 相位敏感掩码 (PSM)

考虑相位信息的掩码：

$$M_{\text{PSM}}(f,t) = \frac{|S(f,t)|}{|X(f,t)|} \cos(\angle S(f,t) - \angle X(f,t))$$

**优势**：
- 保留相位信息
- 更准确的信号估计

### 4.3 多任务学习

同时估计掩码和其他任务：

```python
class MultiTaskNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.shared_encoder = SharedEncoder()
        self.mask_head = MaskHead()
        self.doa_head = DOAHead()
        self.vad_head = VADHead()
    
    def forward(self, x):
        features = self.shared_encoder(x)
        mask = self.mask_head(features)
        doa = self.doa_head(features)
        vad = self.vad_head(features)
        return mask, doa, vad
```

**损失函数**：

$$\mathcal{L} = \mathcal{L}_{\text{mask}} + \alpha \mathcal{L}_{\text{DOA}} + \beta \mathcal{L}_{\text{VAD}}$$

---

## 5. 实现细节

### 5.1 完整流程

```python
import numpy as np
import torch
from scipy.signal import stft, istft

class MaskGuidedBeamformer:
    def __init__(self, mask_net, n_fft=512, hop_length=256):
        self.mask_net = mask_net
        self.n_fft = n_fft
        self.hop_length = hop_length
        
    def process(self, audio, steering_vector):
        """
        参数:
            audio: [P, T] - 多通道音频
            steering_vector: [P, F] - 导向矢量
        
        返回:
            enhanced: [T] - 增强音频
        """
        # 1. STFT
        X = self.multi_channel_stft(audio)  # [P, F, T]
        P, F, T = X.shape
        
        # 2. 提取特征
        X_mag = np.abs(X)  # [P, F, T]
        IPD = self.compute_ipd(X)  # [P*(P-1)/2, F, T]
        
        # 3. 神经网络估计掩码
        with torch.no_grad():
            X_mag_t = torch.from_numpy(X_mag).float()
            IPD_t = torch.from_numpy(IPD).float()
            M_s, M_n = self.mask_net(X_mag_t, IPD_t)
            M_s = M_s.numpy()
            M_n = M_n.numpy()
        
        # 4. 掩码引导协方差估计
        R_s = self.estimate_covariance(X, M_s)  # [F, P, P]
        R_n = self.estimate_covariance(X, M_n)  # [F, P, P]
        
        # 5. 计算MVDR权重
        W = self.compute_mvdr_weights(R_n, steering_vector)  # [F, P]
        
        # 6. 应用波束形成
        Y = np.zeros((F, T), dtype=complex)
        for f in range(F):
            Y[f, :] = W[f, :].conj() @ X[:, f, :]
        
        # 7. iSTFT
        enhanced = self.istft(Y)
        
        return enhanced
    
    def estimate_covariance(self, X, M):
        """掩码引导协方差估计"""
        P, F, T = X.shape
        R = np.zeros((F, P, P), dtype=complex)
        
        for f in range(F):
            # 加权协方差
            X_f = X[:, f, :]  # [P, T]
            M_f = M[f, :]  # [T]
            
            # R = Σ_t M(t) * X(t) * X^H(t) / Σ_t M(t)
            for t in range(T):
                R[f] += M_f[t] * np.outer(X_f[:, t], X_f[:, t].conj())
            
            R[f] /= (M_f.sum() + 1e-8)
        
        return R
    
    def compute_mvdr_weights(self, R_n, d, epsilon=1e-6):
        """计算MVDR权重"""
        F, P, _ = R_n.shape
        W = np.zeros((F, P), dtype=complex)
        
        for f in range(F):
            R_f = R_n[f] + epsilon * np.eye(P)
            d_f = d[:, f]
            
            # MVDR: w = R^{-1}d / (d^H R^{-1} d)
            R_inv_d = np.linalg.solve(R_f, d_f)
            W[f, :] = R_inv_d / (d_f.conj() @ R_inv_d)
        
        return W
```

### 5.2 IPD计算

```python
def compute_ipd(self, X):
    """计算通道间相位差"""
    P, F, T = X.shape
    n_pairs = P * (P - 1) // 2
    IPD = np.zeros((n_pairs, F, T))
    
    idx = 0
    for i in range(P):
        for j in range(i+1, P):
            # IPD = angle(X_i) - angle(X_j)
            IPD[idx] = np.angle(X[i] * X[j].conj())
            idx += 1
    
    return IPD
```

---

## 6. 性能评估

### 6.1 客观指标

```python
def evaluate(enhanced, clean, noisy, fs=16000):
    from pesq import pesq
    from pystoi import stoi
    
    # SI-SNR改善
    si_snr_in = si_snr(noisy, clean)
    si_snr_out = si_snr(enhanced, clean)
    si_snri = si_snr_out - si_snr_in
    
    # PESQ
    pesq_out = pesq(fs, clean, enhanced, 'wb')
    
    # STOI
    stoi_out = stoi(clean, enhanced, fs)
    
    return {
        'SI-SNRi': si_snri,
        'PESQ': pesq_out,
        'STOI': stoi_out
    }
```

### 6.2 典型性能

| 方法 | SI-SNRi (dB) | PESQ | STOI |
|------|--------------|------|------|
| 延迟求和 | 3.5 | 2.1 | 0.75 |
| MVDR | 6.2 | 2.5 | 0.82 |
| 掩码引导MVDR | 9.8 | 3.1 | 0.89 |
| 端到端神经网络 | 11.2 | 3.3 | 0.91 |

---

## 7. 优缺点

### 7.1 优点

1. **结合优势**：神经网络 + 物理约束
2. **数据需求适中**：比纯神经网络少
3. **可解释性好**：保留波束形成结构
4. **泛化能力强**：物理约束提供正则化

### 7.2 缺点

1. **两阶段处理**：掩码估计 + 波束形成
2. **掩码误差传播**：掩码错误影响后续
3. **需要导向矢量**：仍需DOA信息
4. **计算复杂度**：神经网络 + 矩阵运算

---

## 8. 应用场景

### 8.1 智能音箱

**优势**：
- 适应复杂声学环境
- 抑制背景音乐
- 鲁棒的语音增强

**配置**：
- 6-8麦克风圆阵
- LSTM掩码网络
- MVDR波束形成

### 8.2 视频会议

**优势**：
- 多说话人场景
- 动态噪声抑制
- 高音质

**配置**：
- 线性阵列
- 多任务网络（掩码+DOA）
- 自适应波束形成

### 8.3 助听器

**优势**：
- 低延迟
- 低功耗
- 小型化

**配置**：
- 2-3麦克风
- 轻量级网络
- 简化波束形成

---

## 9. 发展趋势

### 9.1 端到端优化

联合训练掩码网络和波束形成器：

$$\mathcal{L} = \mathcal{L}_{\text{output}}(Y, S)$$

通过反向传播同时优化掩码和权重。

### 9.2 注意力机制

使用注意力机制选择时频点：

```python
class AttentionMaskNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.attention = nn.MultiheadAttention(d_model, n_heads)
        
    def forward(self, x):
        # 时频注意力
        attn_out, attn_weights = self.attention(x, x, x)
        mask = self.mask_head(attn_out)
        return mask, attn_weights
```

### 9.3 自监督学习

减少标注数据需求：

- 对比学习
- 掩码预测
- 重构任务

---

## 10. 总结

掩码引导波束形成是传统方法和深度学习的有效结合：

**关键要点**：
1. 神经网络估计软掩码
2. 掩码引导协方差估计
3. 传统波束形成器处理
4. 保留物理约束和可解释性

**适用场景**：
- 需要可解释性的应用
- 数据有限的场景
- 需要物理约束的系统
- 实时处理要求高的应用
