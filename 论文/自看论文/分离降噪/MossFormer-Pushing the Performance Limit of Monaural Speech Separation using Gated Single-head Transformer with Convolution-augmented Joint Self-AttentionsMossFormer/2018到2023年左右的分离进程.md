# 单耳语音分离
从单个重叠混合语音中分离出各个源语音，是一项基本且重要的任务。
## 卷积分离
基于编码表示建模的时域 **Conv-TasNet**[1](https://ar5iv.labs.arxiv.org/html/1809.07454?_immersive_translate_auto_translate=1)最终超越了时频域模型。time-domain audio separation network (Conv-TasNet) 全卷积时域音频分离网络 (Conv-TasNet)
双路径循环神经网络**DPRNN**[2](https://ar5iv.labs.arxiv.org/html/1910.06379?_immersive_translate_auto_translate=1)**提供了一种有效的双路径框架**，通过将编码输入序列拆分成更小的块并分别处理块内和块间序列来处理极长的编码输入序列。由于 DPRNN 能够学习长期时间依赖性，其性能远超 Conv-TasNet。
基于双路径架构的 **VSUNOS**[3](https://ar5iv.labs.arxiv.org/html/2003.01531?_immersive_translate_auto_translate=1) 提出了**门控 RNN 模块**来进一步提升分离性能。然而，基于 RNN 的模型本质上会通过***许多中间状态反复传递历史信息，导致性能不佳***。
## 结合transformer的分离
基于自注意力机制的 Transformer 架构[9](https://arxiv.org/html/1706.03762?_immersive_translate_auto_translate=1) 已经成功集成到双路语音分离流程中。
与 RNN 的循环学习不同，Transformer 能够直接捕捉长距离元素交互。端到端语音分离的双路径变换器网络**DPTNet**[4](https://ar5iv.labs.arxiv.org/html/2007.13975?_immersive_translate_auto_translate=1) 使用改进的 Transformer 架构，其中嵌入了 RNN 来保存序列位置信息，并表现出比 DPRNN 更优异的性能。
**SepFormer**[8]([[2010.13154] 语音分离中，注意力是关键 --- [2010.13154] Attention Is All You Need in Speech Separation](https://ar5iv.labs.arxiv.org/html/2010.13154?_immersive_translate_auto_translate=1) 在标准 Transformer 的基础上加入**多头自注意力机制** (MHSA)，*完全消除了 RNN 循环*，并达到了最佳 (SOTA) 性能。
由于注意力机制计算对输入序列的二次复杂度，DPTNet 和 SepFormer 中的自注意力机制仍然局限于**短上下文大小**。跨块的长距离元素依赖关系仍然通过**中间状态隐式建模**。这一事实可能会对长距离建模能力产生负面影响。与近期 Cramer-Rao 提出的*非线性方法*[10]([[2007.13975] 双路径变换网络：用于端到端单声道语音分离的直接上下文感知建模 --- [2007.13975] Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation](https://ar5iv.labs.arxiv.org/html/2007.13975?_immersive_translate_auto_translate=1) 相比，仍然存在较大的性能差距。此外，现有的双路径 Transformer 模型***未能很好地利用卷积来学习局部特征模式***。
### 时域分离模型
主要采用：编码-->掩码-->解码 这样的三段式端到端的结构，其中的掩码是关键
### 时频域分离模型
由于涉及到频域，涉及傅里叶变换一系列流程，因此必须考虑相位和幅值两个方面的因素，所以常常使用 复值 TF 表示、对多个跨帧和跨频率路径的扫描。
当前的2024年3月缺点：目前的模型架构严重依赖于双向 LSTM 网络，这导致计算需求巨大且推理速度缓慢。因此，它们的可扩展性受到限制，尤其是在要求更高的场景下。