### 1. Windows 默认使用 `spawn` 启动子进程

- 在 Windows 上，Python 的 `multiprocessing` 默认启动方式是 `spawn`。
- `spawn` 会**重新导入主模块、重新初始化所有全局变量、重新加载模型/数据等**，开销非常大。
- 每次 `DataLoader` 启动一个 worker，都会重新执行一遍你的脚本（直到 `if __name__ == '__main__':` 为止），如果你在全局作用域做了 heavy 的操作（比如加载大模型、读取大文件、初始化复杂对象），每个 worker 都要重复做一次 → **严重拖慢启动速度，甚至运行时也卡顿**。

### 2. Linux 默认使用 `fork`

- `fork` 是“复制当前进程状态”，包括内存中的变量、对象等，**几乎零开销**。
- 所以同样的代码，在 Linux 下跑多 worker 通常快很多，启动迅速，运行流畅。

- 如果你的预处理很重（如图像 resize、augmentation、读磁盘、解码视频等），放在 `__getitem__` 是合理的。
- 但如果你的 `Dataset.__init__()` 做了大量全局初始化（如加载整个数据集到内存、构建索引、初始化模型等），而 Windows 使用 `spawn`，那每个 worker 都会重复这些操作 → 内存爆炸 + 启动极慢。
- `num_workers=11` 在 CPU 核心数匹配的情况下理论上是好的，但如果每个 worker 初始化开销太大，反而造成**进程切换开销 > 并行收益**，表现就是“一卡一卡”。
