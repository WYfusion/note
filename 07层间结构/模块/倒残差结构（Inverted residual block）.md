倒残差结构（Inverted Residual Block）由 **MobileNetV2**（2018, Sandler et al.）提出。

---

## 一、核心思想

与残差结构相似，但主分支是**先升维，再卷积，后降维**（与残差结构相反）。

采用 **DW 卷积** 和 **ReLU6 激活函数**。

---

## 二、与残差结构的对比

<img src="../../assets/image-20241114185047599.png" alt="倒残差结构示意图" style="zoom: 33%; display: block; margin: 0 auto;" />

| **特性**      | **残差结构（ResNet）**   | **倒残差结构（MobileNetV2）** |
| ------------- | ------------------------ | ----------------------------- |
| **主分支流程** | 降维 → 卷积 → 升维       | **升维 → 卷积 → 降维**        |
| **形状**      | 两头大、中间小（瓶颈）   | **两头小、中间大（倒瓶颈）**  |
| **卷积类型**  | 标准卷积                 | **深度可分离卷积（DW Conv）** |
| **激活函数**  | ReLU                     | **ReLU6**                     |
| **设计目标**  | 深度网络的梯度传递       | 轻量化网络的效率              |

---

## 三、结构详解

```
输入 x (低维，如24通道)
  │
  ├─ [主分支]
  │   ├─ 1×1 Conv (升维→144) → BN → ReLU6
  │   ├─ 3×3 DW Conv (stride=1或2) → BN → ReLU6
  │   └─ 1×1 Conv (降维→24) → BN（无激活）
  │
  └─ [捷径分支] Identity（仅当stride=1且输入输出通道相同）
      ↓
   逐元素相加 → 输出
```

### 3.1 设计原理

1. **升维扩展**：通过 1×1 卷积将通道数扩展（扩展因子 $t$，通常 $t=6$）
2. **DW 卷积**：在高维空间进行深度可分离卷积，每个通道独立卷积
3. **降维压缩**：通过 1×1 卷积恢复到低维（线性瓶颈）

### 3.2 为什么使用倒瓶颈？

- **DW 卷积的局限**：DW 卷积参数少，表达能力有限
- **高维空间操作**：在扩展后的高维空间进行卷积，增强特征提取能力
- **低维残差连接**：在低维空间进行残差连接，减少内存占用

---

## 四、ReLU6 激活函数

$$y = \text{ReLU6}(x) = \min(\max(x, 0), 6)$$

- **输出范围**：$[0, 6]$
- **设计目的**：适用于低精度（如定点）计算，防止激活值过大

---

## 五、计算量分析

设输入通道 $C_{in}$，输出通道 $C_{out}$，扩展因子 $t$，空间尺寸 $H \times W$，卷积核 $k \times k$：

| **操作**           | **计算量（MACs）**                               |
| ------------------ | ------------------------------------------------ |
| 1×1 升维           | $H \times W \times C_{in} \times t \cdot C_{in}$ |
| $k \times k$ DW    | $H \times W \times t \cdot C_{in} \times k^2$    |
| 1×1 降维           | $H \times W \times t \cdot C_{in} \times C_{out}$ |

**总计**：$HW \cdot C_{in} \cdot (t \cdot C_{in} + t \cdot k^2 + t \cdot C_{out})$

相比标准卷积 $HW \cdot C_{in} \cdot C_{out} \cdot k^2$，计算量大幅降低。
