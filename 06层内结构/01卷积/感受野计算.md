CNN感受野

相对性：CNN中特征图的一个元素**对应于之前某层特征图扫过的子矩阵范围大小**。在CNN中，特征图上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。

绝对性：CNN中感受野的数值也通常指**某一层特征图上的神经元在输入图像（原始图像）上能感知的区域大小**。例如，若某一层特征图的感受野为7×7，表示该层每个神经元能“看到”输入图像中7×7像素的区域。这种定义下，感受野是一个**绝对数值**，直接对应输入图像上的物理范围。
- **绝对性**：感受野的数值最终指向输入图像的物理区域，是网络设计中更常用的指标。
- **相对性**：体现层间特征的传递关系，用于分析局部参数调整的影响。 实际应用中需根据任务需求选择视角，例如设计轻量化模型时需平衡绝对感受野大小与计算量，而在分析特征抽象层级时需关注相对性

## **感受野反向计算公式**

$F(i)=(F(i+1)-1)\times Stride(i)+Size(i)$

1. $F(i)$是第$i$层的感受野大小
2. $Stride(i)$为第$i$层的步距
3. $Size(i)$为第$i$层卷积核或者池化层的尺寸

<img src="../assets/image-20241015210459378.png" alt="image-20241015210459378" style="zoom: 33%;" />

取最上层中特征图的一个元素，则有$\begin{aligned}\mathsf{Pool1:}\quad&\mathsf{F=(1-1)\times2+2=2}\\\mathsf{Conv1:}\quad&\mathsf{F=(2-1)\times2+3=5}\end{aligned}$   其中算得的$2、5$分别是池化、卷积层的感受野尺寸(方形)

---

可以使用$3$层$(3\times3)$的步距为1的卷积核可以实现一个$(7\times7)$的卷积核
$$
\begin{aligned}\mathsf{Conv3\times3(3):}\quad&\mathsf{F=(1-1)\times1+3=3}
\\\mathsf{Conv3\times3(3):}\quad&\mathsf{F=(3-1)\times1+3=5}
\\\mathsf{Conv3\times3(3):}\quad&\mathsf{F=(5-1)\times1+3=7}\end{aligned}
$$

这样可以减少参数

使用$7\times7$卷积核所需参数，与堆叠三个$3\times3$卷积核所需参数(假设输入输出channel为$C$，交叉对应所以为$C^2$)
$$
7\times7×C×C=49C^2\\\mathsf
3\times3×C×C+3\times3×C×C+3\times3×C×C=27C^2
$$

## **感受野前向计算公式**

$$
f(k)=f(k-1)+\left(\left(Size(i)-1\right) * \prod_{i=1}^{k-1} Stride(i)\right)
$$
一般来说第一层感受野大小为卷积核的大小，感受野计算不考虑padding参数。

$f(k)$为第$k$层的感受野大小
$Size(i)$为第$k$层的卷积核尺寸
$Stride(i)$为第$i$层的步长
注意：其中对于步长的累乘只需到$k-1$层即可

举例：

| No. | Layers | Kernel Size | Stride |
| --- | ------ | ----------- | ------ |
| 1   | Conv1  | 3×3         | 1      |
| 2   | Pool1  | 2×2         | 2      |
| 3   | Conv2  | 3×3         | 1      |
| 4   | Pool2  | 2×2         | 2      |
| 5   | Conv3  | 3×3         | 1      |
| 6   | Conv4  | 3×3         | 1      |
| 7   | Pool3  | 2×1         | 2      |

取$f(0)$为1，则有
$$
\begin{aligned}
& f(0)=1 \\
& f(1)=1+(3-1)=3 \\
& f(2)=3+(2-1) \times 1=4 \\
& f(3)=4+(3-1) \times 1 \times 2=8 \\
& f(4)=8+(2-1) \times 1 \times 2 \times 1=10 \\
& f(5)=10+(3-1) \times 1 \times 2 \times 1 \times 2=18 \\
& f(6)=18+(3-1) \times 1 \times 2 \times 1 \times 2 \times 1=26 \\
& f(7)=26+(2-1) \times 1 \times 2 \times 1 \times 2 \times 1 \times 1=30
\end{aligned}
$$


  

  

| **维度**   | **前向计算公式**     | **反向计算公式**    |
| -------- | -------------- | ------------- |
| **递推方向** | 输入层 → 深层       | 深层 → 输入层      |
| **计算逻辑** | 依赖步长连乘，逐层叠加感受野 | 通过解方程或循环逆向推导  |
| **适用场景** | 浅层网络设计、直观分析    | 深层网络优化、动态参数调整 |
| **计算效率** | 需维护中间变量，效率较低   | 无需步长连乘，效率更高   |
