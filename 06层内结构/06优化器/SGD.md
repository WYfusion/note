$SGD$优化器$(Stochastic\ Gradient\ Descent)$
$$
{\Large \displaystyle w_{t+1}=w_t-\alpha\cdot g(w_t)}
$$

$g(w_t)$为$t$时刻对参数$w_t$的梯度损失

##### 缺点：

1. 易受样本噪声影响
2. 可能陷入局部最优解
